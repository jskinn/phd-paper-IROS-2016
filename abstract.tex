% !TEX root = root.tex

% TODO: Re-write after the rest of the paper
One of the critical bottlenecks of computer and robotic vision research has been the extent to which real world image data could be captured for both training and testing purposes. In domains such as robot navigation, certain types of highly relevant data is difficult and labor intensive to obtain - for example, multiple traverses of a road under all possible environmental conditions or from all possible camera viewpoints. In this paper, we investigate how these limitations can be addressed by using a high-fidelity simulation environment to generate image datasets. To achieve this, we use an existing state of the art simulation tool, Unreal Engine 4 by Epic Games, to generate a variety of image datasets that contain task-relevant variation including camera-viewpoint change and time of day changes, and demonstrate that algorithm performance in the real world is similar to in simulation. These datasets enable us to systematically evaluate current state-of-the-art place recognition algorithms at a granularity that was previously impossible, both in terms of comparing algorithms to each other but also evaluating the effect of varying key algorithm parameters. Together, this work opens up new opportunities for development and analysis of algorithms, without the added cost of capturing real-world datasets with which to test the algorithm under development.