% !TEX root = root.tex
Computer vision research typically relies on image datasets collected from the real world to test, train and analyse the algorithms developed. But acquiring the necessary image data from the real world can be difficult, expensive or, for certain kinds of data, outright impossible. For instance, research on algorithms that desire to be viewpoint invariant or condition invariant requires images from a wide variety of viewpoints or a variety of conditions. 

Another key limitation on real-world image datasets is a lack of repeatability. Usually each experimental run or dataset capture is unique, as changes in time of day or time of year or weather all change lighting conditions, sky and, background elements. Even the exact position of the camera will vary at the small scale, shifting pixels and producing similar but distinct images, even in the most static environments.

It is also often difficult to capture a sufficient amount of data from the real world. When working with supervised learning algorithms, such as modern deep-learning neural nets, a large amount of data is required to train and test the network. Crucially, this data must be of sufficient variety that the resulting network can generalize successfully to unseen data rather than over-fitting to the training data.

Further, a reliance on limited real-world datasets in turn limits the ability to demonstrate the generality and limitations of an algorithm. Take for instance the demonstrations of depth invariance in SMART \cite{pepperell2015automatic}, in which the adjusted SMART algorithm is shown to be capable of identifying places given a 4-lane change in depth. No claims are or can be made about the limitations of this technique; over how large a depth-change can the algorithm maintain performance? 100m? 1 km? How does the performance fall off as the depth increases? We cannot answer these questions using real-world data, as collecting the requisite images would be impossible.

In this paper, we demonstrate that many of these issues can be addressed by generating image data on demand from a high-fidelity simulation environment. High-fidelity simulation is capable of generating arbitrary amounts of image data, which can be used to both train and test computer vision algorithms.