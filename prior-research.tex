% !TEX root = root.tex

\subsection{Simulation}

The use of simulation in robotics is not a new idea. Popular robot simulators such as Gazebo \cite{Koenig2004} and Player/Stage \cite{Gerkey2003} have existed for many years, and are commonly used to test robot motion and control. The use of game engines for robot simulation is also not new, with the USARsim project based on the Unreal Tournament 3 engine \cite{Carpin2007}, and other projects using the Unity engine \cite{mattingly2012robot}. Nobody has yet made use of modern, high-fidelity engines such as Unity 5 or Unreal Engine 4 (the successor to the Unreal Tournament 3 engine).

The more specific field of robotic vision has not seen much application of simulation at all, it instead prefers to work from image datasets captured from the real world.  The key requirement for simulation in computer vision is that the simulator is capable of photo-realistic rendering and lighting, which has historically been out of reach for older platforms, including the Unreal Tournament 3 engine or Gazebo. Unreal Engine 4 however has powerful tools for realistic materials and lighting \cite{karis2013real}, which make it possible to create simulated environment that produce images similar to the real world.

Unreal Engine 4 has a number of additional advantages that make it suitable as a simulator platform for computer vision. It is developed and maintained by Epic Games Inc, and uses physics and modelling tools from nVidia, which allow for complex and interactive dynamic environments. It also allows full access to it's source code, allowing a stimulation designer complete control over the simulation. It is also free for non-commercial uses, including research.

\subsection{Place Recognition and Visual SLAM}
A place is defined as a distinct 2D or 3D location in the representation map of environment. In robotic vision, visual places are described using the image features which can be broadly classified into local and global image descriptors. The most common and efficient approaches for recognizing a place revisited by a robot make use of Bag of Words approach with features, for example, SURF in FAB-MAP \cite{Cummins2010} and ORB in ORB-SLAM \cite{Montiel2015} etc. Some extensions of such methods also include building vocabulary online in an incremental fashion or incorporating geometric constraints between words for better performance. These methodologies allow a wide baseline matching of places, but they are brittle towards vast changes in appearance of the environment. On the other hand, use of global image descriptors like BRIEF-GIST \cite{Sunderhauf2011} or patch-normalized downsampled images as in SeqSLAM \cite{Milford2012} allows matching across change in conditions, but lacks robustness towards viewpoint variations. There are some place recognition methods which have proven to work well with both condition and viewpoint variations as in \cite{McManus2014}, \cite{Milford2008} and \cite{Niko2015}. Some of the methods describe places in 3D using only monocular camera by employing Structure from Motion (SfM) techniques. This helps in sparse \cite{Montiel2015}, semi-dense \cite{Engel2014lsd, Mur-Artal2015b} or dense \cite{Newcombe2011} reconstruction of environment for visual SLAM and other similar applications.
\\
The main challenges in place recognition lie in robustness towards both change in conditions and viewpoint of a place. The environments with bland and texture-less images, motion blur, and effects introduced by camera properties like rolling shutter, granular noise etc. make it even more challenging to develop a strong place recognition algorithm.
The visual SLAM systems apart from performing visual place recognition also comprise of visual odometry and a mapping backend. The overall challenges for such systems are related to consistently calculating camera motion between keyframes/frames, relocalizing camera position when tracking fails, handling dynamic changes in the environment, performing efficient loop closures to get rid of scale drift in the map, and efficient 3D map construction.
\\
A robust place recognition or SLAM system needs to be tested for all the challenges mentioned above and in different types of enviroments for a complete analysis of its performance. Such an in-depth analysis is often limited by lack of variety in the test datasets or bias towards chosing a test set that works for the assumptions made by the particular algorithm. The existence of high fidelity simulated enviroment where the content of it can be fully controlled thus provides a great tool for thorough performance analysis and is not being currently done to the extent we present in this paper.